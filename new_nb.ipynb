{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "stocks = ['RELIANCE.NS', 'TATASTEEL.NS', 'HDFCBANK.NS', 'INFY.NS', 'BAJAJ-AUTO.NS', 'ICICIBANK.NS', 'ITC.NS',  'UPL.NS', 'ONGC.NS', 'HINDALCO.NS', 'TITAN.NS', 'COALINDIA.NS', 'INDUSINDBK.NS', 'BAJAJFINSV.NS', 'GRASIM.NS', 'JSWSTEEL.NS']\n",
    "crypto = ['BTC-USD', 'ETH-USD', 'ADA-USD', 'DOGE-USD', 'SOL1-USD', 'LTC-USD', 'BNB-USD', 'AVAX-USD', 'UNI3-USD', 'DOT1-USD', 'SUSHI-USD', 'LINK-USD', 'XRP-USD', 'ALGO-USD', 'EOS-USD', 'XTZ-USD', 'FIL-USD', 'ATOM1-USD', 'TRX-USD', 'MATIC-USD', 'CHZ-USD', 'FTT1-USD', 'NEAR-USD', 'SAND-USD', 'WAVES-USD', 'IOST-USD', 'DASH-USD', 'STORJ-USD', 'ZEC-USD', 'KSM-USD']\n",
    "commodity = ['GC=F', 'SI=F', 'HG=F', 'PL=F', 'PA=F', 'CL=F', 'NG=F', 'RB=F', 'HO=F', 'BZ=F', 'KC=F', 'SB=F', 'CT=F', 'HE=F', 'LE=F', 'GOLD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# # Download historical stock data for a specific ticker\n",
    "# ticker = \"AAPL\"\n",
    "# data = yf.download(ticker, start=\"2018-01-01\", end=\"2023-05-10\")\n",
    "\n",
    "# Define functions to calculate technical indicators\n",
    "def MACD(df, fast=12, slow=26, signal=9):\n",
    "    exp1 = df[\"Close\"].ewm(span=fast, adjust=False).mean()\n",
    "    exp2 = df[\"Close\"].ewm(span=slow, adjust=False).mean()\n",
    "    macd = exp1 - exp2\n",
    "    signal = macd.ewm(span=signal, adjust=False).mean()\n",
    "    return macd, signal\n",
    "\n",
    "def ATR(df, n=14):\n",
    "    high = df[\"High\"]\n",
    "    low = df[\"Low\"]\n",
    "    close = df[\"Close\"]\n",
    "    tr1 = high - low\n",
    "    tr2 = abs(high - close.shift())\n",
    "    tr3 = abs(low - close.shift())\n",
    "    true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    atr = true_range.rolling(n).mean()\n",
    "    return atr\n",
    "\n",
    "def normalized_ATR(df, n=14):\n",
    "    atr = ATR(df, n)\n",
    "    natr = atr / df[\"Close\"] * 100\n",
    "    return natr\n",
    "\n",
    "def momentum(df, n=10):\n",
    "    return df[\"Close\"].diff(n)\n",
    "\n",
    "def CO(df):\n",
    "    adl = (2*df[\"Close\"]-df[\"High\"]-df[\"Low\"])/(df[\"High\"]-df[\"Low\"])*df[\"Volume\"]\n",
    "    ema3 = adl.ewm(span=3, adjust=False).mean()\n",
    "    ema10 = adl.ewm(span=10, adjust=False).mean()\n",
    "    co = ema3 - ema10\n",
    "    return co\n",
    "\n",
    "def OBV(df):\n",
    "    vol = df[\"Volume\"]\n",
    "    change = np.where(df[\"Close\"].diff() > 0, 1, -1)\n",
    "    obv = (vol * change).cumsum()\n",
    "    return obv\n",
    "\n",
    "# def MFI(df, n=14):\n",
    "#     typical_price = (df[\"High\"] + df[\"Low\"] + df[\"Close\"]) / 3\n",
    "#     money_flow = typical_price * df[\"Volume\"]\n",
    "#     pos_flow = np.where(typical_price.diff() > 0, money_flow, 0)\n",
    "#     neg_flow = np.where(typical_price.diff() < 0, money_flow, 0)\n",
    "#     pos_mf = pos_flow.rolling(n).sum()\n",
    "#     neg_mf = neg_flow.rolling(n).sum()\n",
    "#     mf_ratio = pos_mf / neg_mf\n",
    "#     mfi = 100 - (100 / (1 + mf_ratio))\n",
    "#     return mfi\n",
    "# def MFI(df, n=14):\n",
    "#     # Calculate the typical price\n",
    "#     typical_price = (df[\"High\"] + df[\"Low\"] + df[\"Close\"]) / 3\n",
    "#     # Calculate the raw money flow\n",
    "#     raw_money_flow = typical_price * df[\"Volume\"]\n",
    "#     # Calculate the money flow ratio\n",
    "#     positive_flow = np.where(typical_price > typical_price.shift(), raw_money_flow, 0)\n",
    "#     negative_flow = np.where(typical_price < typical_price.shift(), raw_money_flow, 0)\n",
    "#     positive_mf = pd.Series(positive_flow).rolling(window=n, min_periods=0).sum()\n",
    "#     negative_mf = pd.Series(negative_flow).rolling(window=n, min_periods=0).sum()\n",
    "#     money_flow_ratio = positive_mf / negative_mf\n",
    "#     # Calculate the money flow index\n",
    "#     money_flow_index = 100 - (100 / (1 + money_flow_ratio))\n",
    "#     return money_flow_index\n",
    "\n",
    "\n",
    "def MFI(df):\n",
    "    # Calculate the Money Flow Index\n",
    "    typical_price = (df['High'] + df['Low'] + df['Close']) / 3\n",
    "    raw_money_flow = typical_price * df['Volume']\n",
    "    up_flow = np.where(typical_price > typical_price.shift(1), raw_money_flow, 0)\n",
    "    down_flow = np.where(typical_price < typical_price.shift(1), raw_money_flow, 0)\n",
    "    positive_money_flow = np.sum(up_flow)\n",
    "    negative_money_flow = np.sum(down_flow)\n",
    "    money_ratio = np.divide(positive_money_flow, negative_money_flow, where=negative_money_flow!=0)\n",
    "    mfi = np.where(negative_money_flow==0, 100, 100 - (100 / (1 + money_ratio)))\n",
    "    return mfi\n",
    "\n",
    "\n",
    "\n",
    "# def HTDCP(df):\n",
    "#     cycle, trend = pd.core.window.HammingWindow(window_len=11).frequency_response()*100\n",
    "#     hilbert = pd.Series(pd.Series.rolling(df[\"Close\"], window=31, center=True).apply(lambda stocks: np.abs(pd.Series(x).hilbert().real))).ewm(span=21, adjust=False).mean()\n",
    "#     phase = np.degrees(np.arctan((hilbert - hilbert.shift(1)) / 0.0001))\n",
    "#     dcp = ((phase.rolling(14).sum() / 14) - 90) * (-1)\n",
    "#     return dcp\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal.windows import hamming\n",
    "\n",
    "def HTDCP(df):\n",
    "    # Calculate the Hilbert Transform Dominant Cycle Phase\n",
    "    analytic_signal = hilbert(df[\"Close\"])\n",
    "    instantaneous_phase = np.degrees(np.unwrap(np.angle(analytic_signal)))\n",
    "    hilbert_transform = np.abs(analytic_signal)\n",
    "    hilbert_envelope = pd.Series(hilbert_transform).rolling(window=31, center=True, min_periods=1).mean()\n",
    "    hilbert_smoothed = pd.Series(hilbert_envelope).rolling(window=11, center=True, min_periods=1).apply(lambda stocks: np.convolve(x, hamming(11), mode='same'), raw=True)\n",
    "    hilbert_smoothed /= np.sum(hamming(11))\n",
    "    hilbert_difference = np.abs(hilbert_smoothed.diff())\n",
    "    hilbert_smoothed_numpy = np.asarray(hilbert_smoothed)  # convert to numpy array\n",
    "    dcphase = np.degrees(np.unwrap(np.angle(pd.Series(hilbert_smoothed_numpy * np.exp(-1j * instantaneous_phase)).rolling(window=31, center=True).mean())))\n",
    "    return dcphase\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def HTS(df, n=14):\n",
    "#     # Extract the analytic signal using the Hilbert Transform\n",
    "#     hilbert = pd.Series(pd.Series.rolling(df[\"Close\"], window=31, center=True).apply(lambda x: pd.Series(x).hilbert()))\n",
    "#     # Calculate the instantaneous amplitude and phase\n",
    "#     inst_amplitude = np.abs(hilbert)\n",
    "#     inst_phase = np.degrees(np.unwrap(np.angle(hilbert)))\n",
    "#     # Calculate the sine wave\n",
    "#     sinewave = np.sin(np.radians(inst_phase))\n",
    "#     # Smooth the sine wave using an EMA\n",
    "#     hts = pd.Series(sinewave).ewm(span=n, min_periods=n).mean()\n",
    "#     return hts\n",
    "from scipy.signal import hilbert\n",
    "\n",
    "def HTS(df):\n",
    "    # Calculate the Hilbert Transform Sinewave\n",
    "    analytic_signal = hilbert(df['Close'])\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "    instant_phase = np.unwrap(np.angle(analytic_signal))\n",
    "    sinewave = np.sin(instant_phase)\n",
    "    return sinewave\n",
    "\n",
    "\n",
    "# def HTTMM(df):\n",
    "#     # Calculate the Hilbert Transform Trend Market Mode\n",
    "#     imf = pd.core.window.HammingWindow(window_len=11).frequency_response()*100\n",
    "#     hilbert = pd.Series(pd.Series.rolling(df[\"Close\"], window=31, center=True).apply(lambda x: np.abs(pd.Series(x).hilbert().real))).ewm(span=21, adjust=False).mean()\n",
    "#     smoothed_imf = pd.Series(hilbert).ewm(span=14, adjust=False).mean()\n",
    "#     trend = np.where(smoothed_imf > smoothed_imf.shift(), 1, -1)\n",
    "#     return trend\n",
    "\n",
    "\n",
    "# from scipy.signal import hilbert, chirp, find_peaks, peak_widths, welch, windows\n",
    "\n",
    "# def HTTMM(df):\n",
    "#     # Calculate the Hilbert Transform Trend Market Mode\n",
    "#     instantaneous_phase = np.unwrap(np.angle(hilbert(df['Close'])))\n",
    "#     inst_period = np.diff(instantaneous_phase)\n",
    "#     inst_period = np.insert(inst_period, 0, inst_period[0])\n",
    "#     inst_frequency = np.divide(1, inst_period)\n",
    "#     frequency = welch(df['Close'], window='hamming', nperseg=len(df['Close']))[0]\n",
    "#     peak_ind, _ = find_peaks(frequency, prominence=0.1)\n",
    "#     widths = peak_widths(frequency, peak_ind, rel_height=0.5)\n",
    "#     dominant_period = np.mean(widths[0] / len(frequency))\n",
    "#     trend_market_mode = np.mod(np.divide(360, dominant_period) * instantaneous_phase, 360)\n",
    "#     return trend_market_mode\n",
    "\n",
    "\n",
    "from scipy.signal import hilbert, chirp, find_peaks, peak_widths, welch, windows\n",
    "\n",
    "def HTTMM(df):\n",
    "    if df.empty:\n",
    "        return pd.Series()\n",
    "    \n",
    "    # Calculate the Hilbert Transform Trend Market Mode\n",
    "    instantaneous_phase = np.unwrap(np.angle(hilbert(df['Close'])))\n",
    "    inst_period = np.diff(instantaneous_phase)\n",
    "    inst_period = np.insert(inst_period, 0, inst_period[0])\n",
    "    inst_frequency = np.divide(1, inst_period)\n",
    "    frequency = welch(df['Close'], window='hamming', nperseg=len(df['Close']))[0]\n",
    "    peak_ind, _ = find_peaks(frequency, prominence=0.1)\n",
    "    widths = peak_widths(frequency, peak_ind, rel_height=0.5)\n",
    "    dominant_period = np.mean(widths[0] / len(frequency))\n",
    "    trend_market_mode = np.mod(np.divide(360, dominant_period) * instantaneous_phase, 360)\n",
    "    return trend_market_mode\n",
    "\n",
    "# # Create a new dataframe to store the technical indicators\n",
    "# features = pd.DataFrame(index=data.index)\n",
    "\n",
    "# # Calculate the technical indicators\n",
    "# features[\"macd\"], features[\"signal\"] = MACD(data)\n",
    "# features[\"atr\"] = ATR(data)\n",
    "# features[\"natr\"] = normalized_ATR(data)\n",
    "# features[\"momentum\"] = momentum(data)\n",
    "# features[\"co\"] = CO(data)\n",
    "# features[\"obv\"] = OBV(data)\n",
    "# features[\"mfi\"] = MFI(data)\n",
    "# features[\"dcp\"] = HTDCP(data)\n",
    "# features[\"hts\"] = HTS(data)\n",
    "# features[\"httmm\"] = HTTMM(data)\n",
    "\n",
    "# # Print the resulting dataframe\n",
    "# print(features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ta import add_all_ta_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:483: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:484: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:485: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:527: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/opt/homebrew/lib/python3.11/site-packages/ta/wrapper.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "def generate_data(stocks):\n",
    "  data_stock = {}\n",
    "  for stock in stocks:\n",
    "      data_stock[stock] = yf.download(stock, period='2y',interval='1d')\n",
    "  # rate of return over 2 days\n",
    "  for stock in stocks:\n",
    "      data_stock[stock]['return'] = (data_stock[stock]['Close'] / data_stock[stock]['Open']) - 1\n",
    "      data_stock[stock]['return']*=100\n",
    "      #new\n",
    "  for stock in stocks:\n",
    "      data_stock[stock]['macd'], data_stock[stock]['signal'] = MACD(data_stock[stock])\n",
    "\n",
    "  for stock in stocks:\n",
    "      data_stock[stock][\"atr\"] = ATR(data_stock[stock])\n",
    "\n",
    "      data_stock[stock][\"natr\"] = normalized_ATR(data_stock[stock])\n",
    "      data_stock[stock][\"momentum\"] = momentum(data_stock[stock])\n",
    "      data_stock[stock][\"co\"] = CO(data_stock[stock])\n",
    "      data_stock[stock][\"obv\"] = OBV(data_stock[stock])\n",
    "      data_stock[stock][\"mfi\"] = MFI(data_stock[stock])\n",
    "      # data_stock[stock][\"dcp\"] = HTDCP(data_stock[stock])\n",
    "      data_stock[stock][\"hts\"] = HTS(data_stock[stock])\n",
    "      # data_stock[stock][\"httmm\"] = HTTMM(data_stock[stock])\n",
    "\n",
    "  # movig avg 10 and 5 days\n",
    "  for stock in stocks:\n",
    "    data_stock[stock]['ma_10d'] = data_stock[stock]['Close'].rolling(window=10, min_periods=1).mean()\n",
    "    data_stock[stock]['ma_5d'] = data_stock[stock]['Close'].rolling(window=5, min_periods=1).mean()\n",
    "      \n",
    "  # volatility\n",
    "  for stock in stocks:\n",
    "    data_stock[stock]['volatility'] = np.log(data_stock[stock]['Close'] / data_stock[stock]['Close'].shift(1)).rolling(window=10).std() * np.sqrt(252)\n",
    "  # volume\n",
    "  for stock in stocks:\n",
    "    data_stock[stock]['volume'] = data_stock[stock]['Volume']\n",
    "  # rsi\n",
    "  for stock in stocks:\n",
    "    delta = data_stock[stock]['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14, min_periods=1).mean()\n",
    "    avg_loss = loss.rolling(window=14, min_periods=1).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    data_stock[stock]['rsi'] = 100 - (100 / (1 + rs))\n",
    "      \n",
    "  # psychological index\n",
    "  for stock in stocks:\n",
    "    n = 10\n",
    "    data_stock[stock]['up_days'] = data_stock[stock]['Close'] > data_stock[stock]['Close'].shift(1)\n",
    "    data_stock[stock]['Nup'] = data_stock[stock]['up_days'].rolling(window=n).sum()\n",
    "    data_stock[stock]['N'] = n\n",
    "    data_stock[stock]['psychological_index'] = data_stock[stock]['Nup'] / data_stock[stock]['N']\n",
    "  for stock in stocks:\n",
    "    data_stock[stock]['return_prev_day'] = data_stock[stock]['return'].shift(1)\n",
    "    data_stock[stock]['return_prev_week'] = data_stock[stock]['return'].shift(5)\n",
    "    data_stock[stock]['return_prev_fortnight'] = data_stock[stock]['return'].shift(10)\n",
    "  for stock in stocks:\n",
    "    data_stock[stock] = add_all_ta_features(\n",
    "       data_stock[stock], open=\"Open\", high=\"High\", \n",
    "       low=\"Low\", close=\"Close\", volume=\"Volume\"\n",
    "      )\n",
    "  #concatenate\n",
    "  df_stock = pd.concat(data_stock, keys=stocks)\n",
    "\n",
    "  return df_stock\n",
    "\n",
    "data = generate_data(stocks)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.loc['RELIANCE.NS'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.loc['BAJAJ-AUTO.NS'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>return</th>\n",
       "      <th>macd</th>\n",
       "      <th>signal</th>\n",
       "      <th>atr</th>\n",
       "      <th>natr</th>\n",
       "      <th>momentum</th>\n",
       "      <th>co</th>\n",
       "      <th>obv</th>\n",
       "      <th>mfi</th>\n",
       "      <th>hts</th>\n",
       "      <th>...</th>\n",
       "      <th>momentum_ppo</th>\n",
       "      <th>momentum_ppo_signal</th>\n",
       "      <th>momentum_ppo_hist</th>\n",
       "      <th>momentum_pvo</th>\n",
       "      <th>momentum_pvo_signal</th>\n",
       "      <th>momentum_pvo_hist</th>\n",
       "      <th>momentum_kama</th>\n",
       "      <th>others_dr</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">BAJAJ-AUTO.NS</th>\n",
       "      <th>2021-08-03</th>\n",
       "      <td>-0.046999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.915661</td>\n",
       "      <td>2.157839</td>\n",
       "      <td>21.867829</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-408981</td>\n",
       "      <td>57.014797</td>\n",
       "      <td>0.437997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334985</td>\n",
       "      <td>0.334935</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>-1.145273</td>\n",
       "      <td>-1.216227</td>\n",
       "      <td>-0.109326</td>\n",
       "      <td>3821.483124</td>\n",
       "      <td>-0.366162</td>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-04</th>\n",
       "      <td>-0.078227</td>\n",
       "      <td>0.303138</td>\n",
       "      <td>0.060628</td>\n",
       "      <td>81.915661</td>\n",
       "      <td>2.157839</td>\n",
       "      <td>21.867829</td>\n",
       "      <td>-9.123246e+04</td>\n",
       "      <td>-45026</td>\n",
       "      <td>57.014797</td>\n",
       "      <td>0.303570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334985</td>\n",
       "      <td>0.334935</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>-1.145273</td>\n",
       "      <td>-1.216227</td>\n",
       "      <td>-0.109326</td>\n",
       "      <td>3821.483124</td>\n",
       "      <td>0.099265</td>\n",
       "      <td>0.099215</td>\n",
       "      <td>0.099265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-05</th>\n",
       "      <td>-0.605154</td>\n",
       "      <td>-0.519796</td>\n",
       "      <td>-0.055457</td>\n",
       "      <td>81.915661</td>\n",
       "      <td>2.157839</td>\n",
       "      <td>21.867829</td>\n",
       "      <td>-1.618915e+05</td>\n",
       "      <td>-378844</td>\n",
       "      <td>57.014797</td>\n",
       "      <td>0.308358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334985</td>\n",
       "      <td>0.334935</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>-1.145273</td>\n",
       "      <td>-1.216227</td>\n",
       "      <td>-0.109326</td>\n",
       "      <td>3821.483124</td>\n",
       "      <td>-0.345772</td>\n",
       "      <td>-0.346372</td>\n",
       "      <td>-0.246851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-06</th>\n",
       "      <td>0.387428</td>\n",
       "      <td>1.162755</td>\n",
       "      <td>0.188185</td>\n",
       "      <td>81.915661</td>\n",
       "      <td>2.157839</td>\n",
       "      <td>21.867829</td>\n",
       "      <td>-3.877117e+04</td>\n",
       "      <td>125167</td>\n",
       "      <td>57.014797</td>\n",
       "      <td>0.253365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334985</td>\n",
       "      <td>0.334935</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>-1.145273</td>\n",
       "      <td>-1.216227</td>\n",
       "      <td>-0.109326</td>\n",
       "      <td>3821.483124</td>\n",
       "      <td>0.762032</td>\n",
       "      <td>0.759143</td>\n",
       "      <td>0.513300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-09</th>\n",
       "      <td>-0.077757</td>\n",
       "      <td>3.050062</td>\n",
       "      <td>0.760561</td>\n",
       "      <td>81.915661</td>\n",
       "      <td>2.157839</td>\n",
       "      <td>21.867829</td>\n",
       "      <td>-9.287989e+04</td>\n",
       "      <td>521265</td>\n",
       "      <td>57.014797</td>\n",
       "      <td>0.270478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334985</td>\n",
       "      <td>0.334935</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>-1.145273</td>\n",
       "      <td>-1.216227</td>\n",
       "      <td>-0.109326</td>\n",
       "      <td>3821.483124</td>\n",
       "      <td>0.189711</td>\n",
       "      <td>0.189532</td>\n",
       "      <td>0.703985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">UPL.NS</th>\n",
       "      <th>2023-07-28</th>\n",
       "      <td>-0.453818</td>\n",
       "      <td>-13.106796</td>\n",
       "      <td>-12.293273</td>\n",
       "      <td>10.264282</td>\n",
       "      <td>1.641891</td>\n",
       "      <td>-14.399963</td>\n",
       "      <td>1.680294e+05</td>\n",
       "      <td>66589202</td>\n",
       "      <td>53.163926</td>\n",
       "      <td>-0.136375</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.019347</td>\n",
       "      <td>-1.875296</td>\n",
       "      <td>-0.144051</td>\n",
       "      <td>-1.243968</td>\n",
       "      <td>3.501330</td>\n",
       "      <td>-4.745298</td>\n",
       "      <td>641.125949</td>\n",
       "      <td>-0.255281</td>\n",
       "      <td>-0.255608</td>\n",
       "      <td>-20.922139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-31</th>\n",
       "      <td>-0.047998</td>\n",
       "      <td>-13.033696</td>\n",
       "      <td>-12.441358</td>\n",
       "      <td>9.553571</td>\n",
       "      <td>1.529305</td>\n",
       "      <td>-19.099976</td>\n",
       "      <td>-4.394636e+04</td>\n",
       "      <td>61331992</td>\n",
       "      <td>53.163926</td>\n",
       "      <td>-0.130526</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.013683</td>\n",
       "      <td>-1.902973</td>\n",
       "      <td>-0.110710</td>\n",
       "      <td>8.560818</td>\n",
       "      <td>4.513228</td>\n",
       "      <td>4.047591</td>\n",
       "      <td>638.077599</td>\n",
       "      <td>-0.071985</td>\n",
       "      <td>-0.072011</td>\n",
       "      <td>-20.979062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01</th>\n",
       "      <td>0.756846</td>\n",
       "      <td>-12.748120</td>\n",
       "      <td>-12.502710</td>\n",
       "      <td>10.167855</td>\n",
       "      <td>1.625037</td>\n",
       "      <td>-14.250000</td>\n",
       "      <td>1.991959e+06</td>\n",
       "      <td>68897756</td>\n",
       "      <td>53.163926</td>\n",
       "      <td>-0.188652</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.974433</td>\n",
       "      <td>-1.917265</td>\n",
       "      <td>-0.057168</td>\n",
       "      <td>20.370557</td>\n",
       "      <td>7.684694</td>\n",
       "      <td>12.685863</td>\n",
       "      <td>636.428021</td>\n",
       "      <td>0.160077</td>\n",
       "      <td>0.159949</td>\n",
       "      <td>-20.852568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-02</th>\n",
       "      <td>-1.534663</td>\n",
       "      <td>-12.901607</td>\n",
       "      <td>-12.582489</td>\n",
       "      <td>9.885712</td>\n",
       "      <td>1.596659</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>6.401936e+05</td>\n",
       "      <td>65920462</td>\n",
       "      <td>53.163926</td>\n",
       "      <td>-0.169264</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.004301</td>\n",
       "      <td>-1.934672</td>\n",
       "      <td>-0.069629</td>\n",
       "      <td>17.479521</td>\n",
       "      <td>9.643659</td>\n",
       "      <td>7.835862</td>\n",
       "      <td>633.443365</td>\n",
       "      <td>-1.046826</td>\n",
       "      <td>-1.052343</td>\n",
       "      <td>-21.681104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03</th>\n",
       "      <td>-1.967345</td>\n",
       "      <td>-14.366571</td>\n",
       "      <td>-12.939306</td>\n",
       "      <td>11.310717</td>\n",
       "      <td>1.883707</td>\n",
       "      <td>-38.950012</td>\n",
       "      <td>1.867628e+05</td>\n",
       "      <td>59208738</td>\n",
       "      <td>53.163926</td>\n",
       "      <td>-0.359435</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.243050</td>\n",
       "      <td>-1.996348</td>\n",
       "      <td>-0.246702</td>\n",
       "      <td>23.121927</td>\n",
       "      <td>12.339313</td>\n",
       "      <td>10.782614</td>\n",
       "      <td>624.890817</td>\n",
       "      <td>-3.020272</td>\n",
       "      <td>-3.066821</td>\n",
       "      <td>-24.046547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7968 rows  108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            return       macd     signal        atr      natr  \\\n",
       "              Date                                                              \n",
       "BAJAJ-AUTO.NS 2021-08-03 -0.046999   0.000000   0.000000  81.915661  2.157839   \n",
       "              2021-08-04 -0.078227   0.303138   0.060628  81.915661  2.157839   \n",
       "              2021-08-05 -0.605154  -0.519796  -0.055457  81.915661  2.157839   \n",
       "              2021-08-06  0.387428   1.162755   0.188185  81.915661  2.157839   \n",
       "              2021-08-09 -0.077757   3.050062   0.760561  81.915661  2.157839   \n",
       "...                            ...        ...        ...        ...       ...   \n",
       "UPL.NS        2023-07-28 -0.453818 -13.106796 -12.293273  10.264282  1.641891   \n",
       "              2023-07-31 -0.047998 -13.033696 -12.441358   9.553571  1.529305   \n",
       "              2023-08-01  0.756846 -12.748120 -12.502710  10.167855  1.625037   \n",
       "              2023-08-02 -1.534663 -12.901607 -12.582489   9.885712  1.596659   \n",
       "              2023-08-03 -1.967345 -14.366571 -12.939306  11.310717  1.883707   \n",
       "\n",
       "                           momentum            co       obv        mfi  \\\n",
       "              Date                                                       \n",
       "BAJAJ-AUTO.NS 2021-08-03  21.867829  0.000000e+00   -408981  57.014797   \n",
       "              2021-08-04  21.867829 -9.123246e+04    -45026  57.014797   \n",
       "              2021-08-05  21.867829 -1.618915e+05   -378844  57.014797   \n",
       "              2021-08-06  21.867829 -3.877117e+04    125167  57.014797   \n",
       "              2021-08-09  21.867829 -9.287989e+04    521265  57.014797   \n",
       "...                             ...           ...       ...        ...   \n",
       "UPL.NS        2023-07-28 -14.399963  1.680294e+05  66589202  53.163926   \n",
       "              2023-07-31 -19.099976 -4.394636e+04  61331992  53.163926   \n",
       "              2023-08-01 -14.250000  1.991959e+06  68897756  53.163926   \n",
       "              2023-08-02 -20.000000  6.401936e+05  65920462  53.163926   \n",
       "              2023-08-03 -38.950012  1.867628e+05  59208738  53.163926   \n",
       "\n",
       "                               hts  ...  momentum_ppo  momentum_ppo_signal  \\\n",
       "              Date                  ...                                      \n",
       "BAJAJ-AUTO.NS 2021-08-03  0.437997  ...      0.334985             0.334935   \n",
       "              2021-08-04  0.303570  ...      0.334985             0.334935   \n",
       "              2021-08-05  0.308358  ...      0.334985             0.334935   \n",
       "              2021-08-06  0.253365  ...      0.334985             0.334935   \n",
       "              2021-08-09  0.270478  ...      0.334985             0.334935   \n",
       "...                            ...  ...           ...                  ...   \n",
       "UPL.NS        2023-07-28 -0.136375  ...     -2.019347            -1.875296   \n",
       "              2023-07-31 -0.130526  ...     -2.013683            -1.902973   \n",
       "              2023-08-01 -0.188652  ...     -1.974433            -1.917265   \n",
       "              2023-08-02 -0.169264  ...     -2.004301            -1.934672   \n",
       "              2023-08-03 -0.359435  ...     -2.243050            -1.996348   \n",
       "\n",
       "                          momentum_ppo_hist  momentum_pvo  \\\n",
       "              Date                                          \n",
       "BAJAJ-AUTO.NS 2021-08-03           0.010505     -1.145273   \n",
       "              2021-08-04           0.010505     -1.145273   \n",
       "              2021-08-05           0.010505     -1.145273   \n",
       "              2021-08-06           0.010505     -1.145273   \n",
       "              2021-08-09           0.010505     -1.145273   \n",
       "...                                     ...           ...   \n",
       "UPL.NS        2023-07-28          -0.144051     -1.243968   \n",
       "              2023-07-31          -0.110710      8.560818   \n",
       "              2023-08-01          -0.057168     20.370557   \n",
       "              2023-08-02          -0.069629     17.479521   \n",
       "              2023-08-03          -0.246702     23.121927   \n",
       "\n",
       "                          momentum_pvo_signal  momentum_pvo_hist  \\\n",
       "              Date                                                 \n",
       "BAJAJ-AUTO.NS 2021-08-03            -1.216227          -0.109326   \n",
       "              2021-08-04            -1.216227          -0.109326   \n",
       "              2021-08-05            -1.216227          -0.109326   \n",
       "              2021-08-06            -1.216227          -0.109326   \n",
       "              2021-08-09            -1.216227          -0.109326   \n",
       "...                                       ...                ...   \n",
       "UPL.NS        2023-07-28             3.501330          -4.745298   \n",
       "              2023-07-31             4.513228           4.047591   \n",
       "              2023-08-01             7.684694          12.685863   \n",
       "              2023-08-02             9.643659           7.835862   \n",
       "              2023-08-03            12.339313          10.782614   \n",
       "\n",
       "                          momentum_kama  others_dr  others_dlr  others_cr  \n",
       "              Date                                                         \n",
       "BAJAJ-AUTO.NS 2021-08-03    3821.483124  -0.366162    0.046617   0.000000  \n",
       "              2021-08-04    3821.483124   0.099265    0.099215   0.099265  \n",
       "              2021-08-05    3821.483124  -0.345772   -0.346372  -0.246851  \n",
       "              2021-08-06    3821.483124   0.762032    0.759143   0.513300  \n",
       "              2021-08-09    3821.483124   0.189711    0.189532   0.703985  \n",
       "...                                 ...        ...         ...        ...  \n",
       "UPL.NS        2023-07-28     641.125949  -0.255281   -0.255608 -20.922139  \n",
       "              2023-07-31     638.077599  -0.071985   -0.072011 -20.979062  \n",
       "              2023-08-01     636.428021   0.160077    0.159949 -20.852568  \n",
       "              2023-08-02     633.443365  -1.046826   -1.052343 -21.681104  \n",
       "              2023-08-03     624.890817  -3.020272   -3.066821 -24.046547  \n",
       "\n",
       "[7968 rows x 108 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled = data.groupby(level=0).apply(lambda x: x.fillna(x.mean()))\n",
    "df_filled = df_filled.fillna(0)\n",
    "# features = [\n",
    "#     'return_2d', 'ma_10d', 'ma_5d', 'volatility', 'rsi', 'volume','return_prev_day','return_prev_week',\n",
    "#     'return_prev_fortnight','psychological_index','atr','momentum','co','obv','mfi','hts'\n",
    "# ]\n",
    "features = data.columns\n",
    "# remove open, high, low, close, volume\n",
    "features = features.drop(['Open','High','Low','Close','Volume','Adj Close'])\n",
    "data_stock = df_filled[features]\n",
    "data_stock = data_stock.reset_index(level=0, drop=True)\n",
    "data_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>return</th>\n",
       "      <td>498.0</td>\n",
       "      <td>-0.023372</td>\n",
       "      <td>1.401885</td>\n",
       "      <td>-6.454618</td>\n",
       "      <td>-0.883882</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>0.787628</td>\n",
       "      <td>5.281757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macd</th>\n",
       "      <td>498.0</td>\n",
       "      <td>7.137308</td>\n",
       "      <td>37.266597</td>\n",
       "      <td>-60.507392</td>\n",
       "      <td>-22.765438</td>\n",
       "      <td>4.463061</td>\n",
       "      <td>32.334598</td>\n",
       "      <td>93.166771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signal</th>\n",
       "      <td>498.0</td>\n",
       "      <td>7.176838</td>\n",
       "      <td>34.127808</td>\n",
       "      <td>-53.997494</td>\n",
       "      <td>-19.629632</td>\n",
       "      <td>5.684578</td>\n",
       "      <td>30.333335</td>\n",
       "      <td>87.543320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atr</th>\n",
       "      <td>498.0</td>\n",
       "      <td>53.388520</td>\n",
       "      <td>13.347621</td>\n",
       "      <td>28.250017</td>\n",
       "      <td>44.553563</td>\n",
       "      <td>51.191040</td>\n",
       "      <td>60.878540</td>\n",
       "      <td>86.892857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natr</th>\n",
       "      <td>498.0</td>\n",
       "      <td>2.144393</td>\n",
       "      <td>0.528264</td>\n",
       "      <td>1.131608</td>\n",
       "      <td>1.802268</td>\n",
       "      <td>2.059242</td>\n",
       "      <td>2.497299</td>\n",
       "      <td>3.504310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momentum_pvo_hist</th>\n",
       "      <td>498.0</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>4.869611</td>\n",
       "      <td>-10.896764</td>\n",
       "      <td>-3.222274</td>\n",
       "      <td>-0.563608</td>\n",
       "      <td>1.854736</td>\n",
       "      <td>21.877056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momentum_kama</th>\n",
       "      <td>498.0</td>\n",
       "      <td>2488.000450</td>\n",
       "      <td>115.010926</td>\n",
       "      <td>2171.543410</td>\n",
       "      <td>2397.578949</td>\n",
       "      <td>2488.057172</td>\n",
       "      <td>2575.407927</td>\n",
       "      <td>2773.873600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others_dr</th>\n",
       "      <td>498.0</td>\n",
       "      <td>0.014907</td>\n",
       "      <td>1.735466</td>\n",
       "      <td>-15.864134</td>\n",
       "      <td>-0.842570</td>\n",
       "      <td>0.040756</td>\n",
       "      <td>0.871331</td>\n",
       "      <td>6.019820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others_dlr</th>\n",
       "      <td>498.0</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>1.584533</td>\n",
       "      <td>-8.133818</td>\n",
       "      <td>-0.837476</td>\n",
       "      <td>0.040747</td>\n",
       "      <td>0.867557</td>\n",
       "      <td>5.845587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others_cr</th>\n",
       "      <td>498.0</td>\n",
       "      <td>18.855376</td>\n",
       "      <td>6.724790</td>\n",
       "      <td>-0.507728</td>\n",
       "      <td>14.166567</td>\n",
       "      <td>18.875581</td>\n",
       "      <td>23.572624</td>\n",
       "      <td>36.120230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count         mean         std          min          25%  \\\n",
       "return             498.0    -0.023372    1.401885    -6.454618    -0.883882   \n",
       "macd               498.0     7.137308   37.266597   -60.507392   -22.765438   \n",
       "signal             498.0     7.176838   34.127808   -53.997494   -19.629632   \n",
       "atr                498.0    53.388520   13.347621    28.250017    44.553563   \n",
       "natr               498.0     2.144393    0.528264     1.131608     1.802268   \n",
       "...                  ...          ...         ...          ...          ...   \n",
       "momentum_pvo_hist  498.0     0.008003    4.869611   -10.896764    -3.222274   \n",
       "momentum_kama      498.0  2488.000450  115.010926  2171.543410  2397.578949   \n",
       "others_dr          498.0     0.014907    1.735466   -15.864134    -0.842570   \n",
       "others_dlr         498.0     0.034309    1.584533    -8.133818    -0.837476   \n",
       "others_cr          498.0    18.855376    6.724790    -0.507728    14.166567   \n",
       "\n",
       "                           50%          75%          max  \n",
       "return                0.005962     0.787628     5.281757  \n",
       "macd                  4.463061    32.334598    93.166771  \n",
       "signal                5.684578    30.333335    87.543320  \n",
       "atr                  51.191040    60.878540    86.892857  \n",
       "natr                  2.059242     2.497299     3.504310  \n",
       "...                        ...          ...          ...  \n",
       "momentum_pvo_hist    -0.563608     1.854736    21.877056  \n",
       "momentum_kama      2488.057172  2575.407927  2773.873600  \n",
       "others_dr             0.040756     0.871331     6.019820  \n",
       "others_dlr            0.040747     0.867557     5.845587  \n",
       "others_cr            18.875581    23.572624    36.120230  \n",
       "\n",
       "[107 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stock.loc['RELIANCE.NS'].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>return</th>\n",
       "      <th>macd</th>\n",
       "      <th>signal</th>\n",
       "      <th>atr</th>\n",
       "      <th>natr</th>\n",
       "      <th>momentum</th>\n",
       "      <th>co</th>\n",
       "      <th>obv</th>\n",
       "      <th>mfi</th>\n",
       "      <th>hts</th>\n",
       "      <th>...</th>\n",
       "      <th>momentum_ppo</th>\n",
       "      <th>momentum_ppo_signal</th>\n",
       "      <th>momentum_ppo_hist</th>\n",
       "      <th>momentum_pvo</th>\n",
       "      <th>momentum_pvo_signal</th>\n",
       "      <th>momentum_pvo_hist</th>\n",
       "      <th>momentum_kama</th>\n",
       "      <th>others_dr</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>4.980000e+02</td>\n",
       "      <td>4.980000e+02</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.060703</td>\n",
       "      <td>13.603356</td>\n",
       "      <td>13.214289</td>\n",
       "      <td>81.915661</td>\n",
       "      <td>2.157839</td>\n",
       "      <td>21.867829</td>\n",
       "      <td>-1464.163666</td>\n",
       "      <td>7.598501e+06</td>\n",
       "      <td>5.701480e+01</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334985</td>\n",
       "      <td>0.334935</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>-1.145273</td>\n",
       "      <td>-1.216227</td>\n",
       "      <td>-0.109326</td>\n",
       "      <td>3821.483124</td>\n",
       "      <td>0.055631</td>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.367508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.347858</td>\n",
       "      <td>55.423179</td>\n",
       "      <td>52.177601</td>\n",
       "      <td>17.092519</td>\n",
       "      <td>0.520363</td>\n",
       "      <td>154.438550</td>\n",
       "      <td>100398.074024</td>\n",
       "      <td>5.614458e+06</td>\n",
       "      <td>1.422514e-14</td>\n",
       "      <td>0.099914</td>\n",
       "      <td>...</td>\n",
       "      <td>1.434453</td>\n",
       "      <td>1.344027</td>\n",
       "      <td>0.441135</td>\n",
       "      <td>10.244379</td>\n",
       "      <td>7.052500</td>\n",
       "      <td>6.587461</td>\n",
       "      <td>376.556967</td>\n",
       "      <td>1.404542</td>\n",
       "      <td>1.403313</td>\n",
       "      <td>10.440160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.231660</td>\n",
       "      <td>-134.407518</td>\n",
       "      <td>-118.636531</td>\n",
       "      <td>48.446411</td>\n",
       "      <td>1.192395</td>\n",
       "      <td>-415.349854</td>\n",
       "      <td>-480382.278110</td>\n",
       "      <td>-3.166671e+06</td>\n",
       "      <td>5.701480e+01</td>\n",
       "      <td>-0.199466</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.789158</td>\n",
       "      <td>-3.368783</td>\n",
       "      <td>-1.304788</td>\n",
       "      <td>-23.252670</td>\n",
       "      <td>-19.259819</td>\n",
       "      <td>-11.602282</td>\n",
       "      <td>3195.054897</td>\n",
       "      <td>-5.457210</td>\n",
       "      <td>-5.611765</td>\n",
       "      <td>-18.886161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.822751</td>\n",
       "      <td>-17.125715</td>\n",
       "      <td>-14.594805</td>\n",
       "      <td>68.416940</td>\n",
       "      <td>1.776414</td>\n",
       "      <td>-68.437256</td>\n",
       "      <td>-59599.214143</td>\n",
       "      <td>2.827672e+06</td>\n",
       "      <td>5.701480e+01</td>\n",
       "      <td>-0.067956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399513</td>\n",
       "      <td>-0.245770</td>\n",
       "      <td>-0.227780</td>\n",
       "      <td>-8.593604</td>\n",
       "      <td>-6.493803</td>\n",
       "      <td>-4.278654</td>\n",
       "      <td>3622.377812</td>\n",
       "      <td>-0.672857</td>\n",
       "      <td>-0.675131</td>\n",
       "      <td>-5.694909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.086224</td>\n",
       "      <td>17.099795</td>\n",
       "      <td>12.682025</td>\n",
       "      <td>80.164280</td>\n",
       "      <td>2.114938</td>\n",
       "      <td>21.867829</td>\n",
       "      <td>-7032.835700</td>\n",
       "      <td>8.009706e+06</td>\n",
       "      <td>5.701480e+01</td>\n",
       "      <td>-0.022110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453004</td>\n",
       "      <td>0.341617</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>-1.241184</td>\n",
       "      <td>-1.216227</td>\n",
       "      <td>-0.940610</td>\n",
       "      <td>3753.080262</td>\n",
       "      <td>0.035756</td>\n",
       "      <td>0.038932</td>\n",
       "      <td>-1.851392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.693644</td>\n",
       "      <td>49.205876</td>\n",
       "      <td>47.966979</td>\n",
       "      <td>91.193678</td>\n",
       "      <td>2.433700</td>\n",
       "      <td>118.287476</td>\n",
       "      <td>54541.576967</td>\n",
       "      <td>1.092821e+07</td>\n",
       "      <td>5.701480e+01</td>\n",
       "      <td>0.059144</td>\n",
       "      <td>...</td>\n",
       "      <td>1.285030</td>\n",
       "      <td>1.263042</td>\n",
       "      <td>0.296749</td>\n",
       "      <td>5.517813</td>\n",
       "      <td>3.313134</td>\n",
       "      <td>2.531253</td>\n",
       "      <td>3837.475642</td>\n",
       "      <td>0.785678</td>\n",
       "      <td>0.782608</td>\n",
       "      <td>2.158654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.208739</td>\n",
       "      <td>142.330512</td>\n",
       "      <td>137.943757</td>\n",
       "      <td>130.396432</td>\n",
       "      <td>3.587814</td>\n",
       "      <td>480.800049</td>\n",
       "      <td>344595.402840</td>\n",
       "      <td>1.990074e+07</td>\n",
       "      <td>5.701480e+01</td>\n",
       "      <td>0.437997</td>\n",
       "      <td>...</td>\n",
       "      <td>3.405188</td>\n",
       "      <td>3.255042</td>\n",
       "      <td>1.230618</td>\n",
       "      <td>41.983369</td>\n",
       "      <td>18.200461</td>\n",
       "      <td>37.193411</td>\n",
       "      <td>4817.996416</td>\n",
       "      <td>5.900632</td>\n",
       "      <td>5.733104</td>\n",
       "      <td>28.817720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           return        macd      signal         atr        natr    momentum  \\\n",
       "count  498.000000  498.000000  498.000000  498.000000  498.000000  498.000000   \n",
       "mean    -0.060703   13.603356   13.214289   81.915661    2.157839   21.867829   \n",
       "std      1.347858   55.423179   52.177601   17.092519    0.520363  154.438550   \n",
       "min     -5.231660 -134.407518 -118.636531   48.446411    1.192395 -415.349854   \n",
       "25%     -0.822751  -17.125715  -14.594805   68.416940    1.776414  -68.437256   \n",
       "50%     -0.086224   17.099795   12.682025   80.164280    2.114938   21.867829   \n",
       "75%      0.693644   49.205876   47.966979   91.193678    2.433700  118.287476   \n",
       "max      5.208739  142.330512  137.943757  130.396432    3.587814  480.800049   \n",
       "\n",
       "                  co           obv           mfi         hts  ...  \\\n",
       "count     498.000000  4.980000e+02  4.980000e+02  498.000000  ...   \n",
       "mean    -1464.163666  7.598501e+06  5.701480e+01   -0.000141  ...   \n",
       "std    100398.074024  5.614458e+06  1.422514e-14    0.099914  ...   \n",
       "min   -480382.278110 -3.166671e+06  5.701480e+01   -0.199466  ...   \n",
       "25%    -59599.214143  2.827672e+06  5.701480e+01   -0.067956  ...   \n",
       "50%     -7032.835700  8.009706e+06  5.701480e+01   -0.022110  ...   \n",
       "75%     54541.576967  1.092821e+07  5.701480e+01    0.059144  ...   \n",
       "max    344595.402840  1.990074e+07  5.701480e+01    0.437997  ...   \n",
       "\n",
       "       momentum_ppo  momentum_ppo_signal  momentum_ppo_hist  momentum_pvo  \\\n",
       "count    498.000000           498.000000         498.000000    498.000000   \n",
       "mean       0.334985             0.334935           0.010505     -1.145273   \n",
       "std        1.434453             1.344027           0.441135     10.244379   \n",
       "min       -3.789158            -3.368783          -1.304788    -23.252670   \n",
       "25%       -0.399513            -0.245770          -0.227780     -8.593604   \n",
       "50%        0.453004             0.341617           0.010505     -1.241184   \n",
       "75%        1.285030             1.263042           0.296749      5.517813   \n",
       "max        3.405188             3.255042           1.230618     41.983369   \n",
       "\n",
       "       momentum_pvo_signal  momentum_pvo_hist  momentum_kama   others_dr  \\\n",
       "count           498.000000         498.000000     498.000000  498.000000   \n",
       "mean             -1.216227          -0.109326    3821.483124    0.055631   \n",
       "std               7.052500           6.587461     376.556967    1.404542   \n",
       "min             -19.259819         -11.602282    3195.054897   -5.457210   \n",
       "25%              -6.493803          -4.278654    3622.377812   -0.672857   \n",
       "50%              -1.216227          -0.940610    3753.080262    0.035756   \n",
       "75%               3.313134           2.531253    3837.475642    0.785678   \n",
       "max              18.200461          37.193411    4817.996416    5.900632   \n",
       "\n",
       "       others_dlr   others_cr  \n",
       "count  498.000000  498.000000  \n",
       "mean     0.046617    0.367508  \n",
       "std      1.403313   10.440160  \n",
       "min     -5.611765  -18.886161  \n",
       "25%     -0.675131   -5.694909  \n",
       "50%      0.038932   -1.851392  \n",
       "75%      0.782608    2.158654  \n",
       "max      5.733104   28.817720  \n",
       "\n",
       "[8 rows x 107 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stock.loc['BAJAJ-AUTO.NS'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stock:\n",
    "    name = None\n",
    "    data = None\n",
    "    scaler = None\n",
    "    lstm_data =  None\n",
    "    scaled_data = None\n",
    "    def __init__(self, name, data):\n",
    "        self.data = data\n",
    "        self.name = name\n",
    "        \n",
    "    def prepare_lstm_data(self, lookback):\n",
    "        X = []\n",
    "        y = []\n",
    "        for i in range(lookback, len(self.data)):\n",
    "            X.append(self.data.iloc[i-lookback:i])\n",
    "            y.append(self.data.iloc[i][\"return\"])\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        self.lstm_data = {\n",
    "            'X': X,\n",
    "            'y': y\n",
    "        }\n",
    "        return self.lstm_data\n",
    "    \n",
    "    def prepare_scaled_data(self, scaler):\n",
    "        self.scaler = scaler()\n",
    "        self.scaled_data = self.scaler.fit_transform(self.data)\n",
    "\n",
    "    def scale(self, scaler):\n",
    "        self.scalerX = scaler()\n",
    "        self.scalerY = scaler()\n",
    "\n",
    "        shapeX = self.lstm_data['X'].shape\n",
    "        reshaped_x = self.lstm_data['X'].reshape((shapeX[0]*shapeX[1], shapeX[2]))\n",
    "        self.lstm_data['X'] = self.scalerX.fit_transform(reshaped_x).reshape(shapeX)\n",
    "\n",
    "        shapeY = self.lstm_data['y'].shape\n",
    "        reshaped_y = self.lstm_data['y'].reshape((shapeY[0], 1))\n",
    "        self.lstm_data['y'] = self.scalerY.fit_transform(reshaped_y).reshape(shapeY[0])\n",
    "\n",
    "        print(self.name, self.lstm_data['X'].shape, self.lstm_data['y'].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELIANCE.NS (488, 10, 108) (488,)\n",
      "TATASTEEL.NS (488, 10, 108) (488,)\n",
      "HDFCBANK.NS (488, 10, 108) (488,)\n",
      "INFY.NS (488, 10, 108) (488,)\n",
      "BAJAJ-AUTO.NS (488, 10, 108) (488,)\n",
      "ICICIBANK.NS (488, 10, 108) (488,)\n",
      "ITC.NS (488, 10, 108) (488,)\n",
      "UPL.NS (488, 10, 108) (488,)\n",
      "ONGC.NS (488, 10, 108) (488,)\n",
      "HINDALCO.NS (488, 10, 108) (488,)\n",
      "TITAN.NS (488, 10, 108) (488,)\n",
      "COALINDIA.NS (488, 10, 108) (488,)\n",
      "INDUSINDBK.NS (488, 10, 108) (488,)\n",
      "BAJAJFINSV.NS (488, 10, 108) (488,)\n",
      "GRASIM.NS (488, 10, 108) (488,)\n",
      "JSWSTEEL.NS (488, 10, 108) (488,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "all_stocks = []\n",
    "for stock in stocks:\n",
    "    s = Stock(stock, data_stock.loc[stock])\n",
    "    s.prepare_lstm_data(lookback=10)\n",
    "    # s.scale(StandardScaler)\n",
    "    s.scale(MinMaxScaler)\n",
    "    all_stocks.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7968, 108)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge all stocks into one \n",
    "tX = []\n",
    "ty = []\n",
    "t = []\n",
    "for stock in all_stocks:\n",
    "    stock.prepare_scaled_data(MinMaxScaler)\n",
    "    t.append(stock.scaled_data)\n",
    "\n",
    "t = np.array(t)\n",
    "t = t.reshape((t.shape[0]*t.shape[1], t.shape[2]))\n",
    "\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13600592 0.21767636 0.22741927 0.21283963 0.21188151 0.16818066\n",
      " 0.14076332 0.26509074 0.         0.20886496 0.25379187 0.2435454\n",
      " 0.19045233 0.11651363 0.1996235  0.49975383 0.19495839 0.\n",
      " 0.19495839 0.13590313 0.13560348 0.13520249 0.25513824 0.26650311\n",
      " 0.20010471 0.21427185 0.15845689 0.1845087  0.21176245 0.2524672\n",
      " 0.20849097 0.27972699 0.25863888 0.24546997 0.25410957 0.19670503\n",
      " 0.19972893 0.25113673 0.21522917 0.25038054 0.25095817 0.25432719\n",
      " 0.20351868 0.17753197 0.42721142 0.38416236 0.26329262 0.24837613\n",
      " 0.25152658 0.20294822 0.30528871 0.16353016 0.2135373  0.21530073\n",
      " 0.22429639 0.18379963 0.25260611 0.25924691 0.2540099  0.2602727\n",
      " 0.20004007 0.19654266 0.20147689 0.21822193 0.19634179 0.16348729\n",
      " 0.20707854 0.21113823 0.19586746 0.24384088 0.25194834 0.25143812\n",
      " 0.2687552  0.40054346 0.20557199 0.17938487 0.18961108 0.17984512\n",
      " 0.24819019 0.26802815 0.35409665 0.34972748 0.3142795  0.18418263\n",
      " 0.17758666 0.21390841 0.21627867 0.20367362 0.35428792 0.32184004\n",
      " 0.30830582 0.22873718 0.19480667 0.30547589 0.29628928 0.30547589\n",
      " 0.20090159 0.17114914 0.21122971 0.2207729  0.18282491 0.18491063\n",
      " 0.20526215 0.15080014 0.25347025 0.16530946 0.15475839 0.2284567 ]\n"
     ]
    }
   ],
   "source": [
    "print(np.std(t, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA, PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def get_pca(data, n_components=2):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(data)\n",
    "    return pca.transform(data)\n",
    "\n",
    "def get_kpca(data, n_components=2, kernel='rbf'):\n",
    "    kpca = KernelPCA(n_components=n_components, kernel=kernel, n_jobs=-1)\n",
    "    kpca.fit(data)\n",
    "    return kpca.transform(data)\n",
    "\n",
    "def get_tsne(data, n_components=2, perplexity=30, n_iter=1000):\n",
    "\n",
    "    tsne = TSNE(n_components=n_components, perplexity=perplexity, n_iter=n_iter, n_jobs=-1)\n",
    "    return tsne.fit_transform(data)\n",
    "\n",
    "kpcaData = get_kpca(t, n_components=50, kernel='rbf')\n",
    "tsneData = get_tsne(kpcaData, n_components=2, perplexity=20, n_iter=2000)\n",
    "\n",
    "# plot the data\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(tsneData[:,0], tsneData[:,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "np.save('tsneData.npy', tsneData)\n",
    "np.save('kpcaData.npy', kpcaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELIANCE.NS (488, 10, 108) (488,)\n",
      "TATASTEEL.NS (488, 10, 108) (488,)\n",
      "HDFCBANK.NS (488, 10, 108) (488,)\n",
      "INFY.NS (488, 10, 108) (488,)\n",
      "BAJAJ-AUTO.NS (488, 10, 108) (488,)\n",
      "ICICIBANK.NS (488, 10, 108) (488,)\n",
      "ITC.NS (488, 10, 108) (488,)\n",
      "UPL.NS (488, 10, 108) (488,)\n",
      "ONGC.NS (488, 10, 108) (488,)\n",
      "HINDALCO.NS (488, 10, 108) (488,)\n",
      "TITAN.NS (488, 10, 108) (488,)\n",
      "COALINDIA.NS (488, 10, 108) (488,)\n",
      "INDUSINDBK.NS (488, 10, 108) (488,)\n",
      "BAJAJFINSV.NS (488, 10, 108) (488,)\n",
      "GRASIM.NS (488, 10, 108) (488,)\n",
      "JSWSTEEL.NS (488, 10, 108) (488,)\n"
     ]
    }
   ],
   "source": [
    "for s in all_stocks:\n",
    "    print(s.name,s.lstm_data['X'].shape,s.lstm_data['y'].shape)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all stocks\n",
    "X = []\n",
    "y = []\n",
    "for stock in all_stocks:\n",
    "    X.append(stock.lstm_data['X'])\n",
    "    y.append(stock.lstm_data['y'])\n",
    "X = np.concatenate(X)\n",
    "y = np.concatenate(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7808, 10, 108), (7808,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6246, 10, 108), (1562, 10, 108), (6246,), (1562,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train = X[:int(len(X)*0.8)]\n",
    "X_test = X[int(len(X)*0.8):]\n",
    "y_train = y[:int(len(y)*0.8)]\n",
    "y_test = y[int(len(y)*0.8):]\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the LSTM model\n",
    "model_stock = tf.keras.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True,input_shape=(X_train.shape[1], X_train.shape[2]))),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "# Compile the model\n",
    "model_stock.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "176/176 [==============================] - 7s 22ms/step - loss: 0.0381 - val_loss: 0.0201\n",
      "Epoch 2/10\n",
      "176/176 [==============================] - 4s 20ms/step - loss: 0.0178 - val_loss: 0.0215\n",
      "Epoch 3/10\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.0176 - val_loss: 0.0236\n",
      "Epoch 4/10\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.0174 - val_loss: 0.0231\n",
      "Epoch 5/10\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.0181 - val_loss: 0.0203\n",
      "Epoch 6/10\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.0179 - val_loss: 0.0213\n",
      "Epoch 7/10\n",
      "176/176 [==============================] - 5s 30ms/step - loss: 0.0181 - val_loss: 0.0220\n",
      "Epoch 8/10\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.0184 - val_loss: 0.0221\n",
      "Epoch 9/10\n",
      "176/176 [==============================] - 5s 26ms/step - loss: 0.0180 - val_loss: 0.0215\n",
      "Epoch 10/10\n",
      "176/176 [==============================] - 4s 25ms/step - loss: 0.0178 - val_loss: 0.0211\n"
     ]
    }
   ],
   "source": [
    "history = model_stock.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stock.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a data loader for the dataset\n",
    "\n",
    "import torch\n",
    "# get dataloader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "dataset = [X_train, y_train, X_test, y_test]\n",
    "train_dataset = TensorDataset(torch.tensor(dataset[0]), torch.tensor(dataset[1]))\n",
    "test_dataset = TensorDataset(torch.tensor(dataset[2]), torch.tensor(dataset[3]))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/harshit/miniforge3/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# create same model in pytorch\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.LSTM(input_size = (X_train.shape[1],X_train.shape[2]), hidden_size=128, bidirectional=True, batch_first=True),\n",
    "            nn.LSTM(64, bidirectional=True, batch_first=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RNNBase.__init__() missing 1 required positional argument: 'hidden_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m Net()\n\u001b[1;32m      2\u001b[0m \u001b[39m# model no.of parameters\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mnumel() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mparameters() \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mrequires_grad))\n",
      "Cell \u001b[0;32mIn[24], line 12\u001b[0m, in \u001b[0;36mNet.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     10\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     11\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m---> 12\u001b[0m         nn\u001b[39m.\u001b[39;49mLSTM(\u001b[39m128\u001b[39;49m, bidirectional\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, batch_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m     13\u001b[0m         nn\u001b[39m.\u001b[39mLSTM(\u001b[39m64\u001b[39m, bidirectional\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     14\u001b[0m         nn\u001b[39m.\u001b[39mDropout(\u001b[39m0.1\u001b[39m),\n\u001b[1;32m     15\u001b[0m         nn\u001b[39m.\u001b[39mLinear(\u001b[39m128\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/rnn.py:732\u001b[0m, in \u001b[0;36mLSTM.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 732\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mLSTM\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: RNNBase.__init__() missing 1 required positional argument: 'hidden_size'"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "# model no.of parameters\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "model_stock.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_stock.predict(X_test)\n",
    "y_pred = stock.scalerY.inverse_transform(y_pred)\n",
    "y_true = stock.scalerY.inverse_transform(y_test.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot error\n",
    "plt.plot(y_true, label='true')\n",
    "plt.plot(y_pred, label='pred')\n",
    "# plt.plot(y_true-y_pred, label='error')\n",
    "plt.legend()\n",
    "# increase plot width\n",
    "plt.rcParams[\"figure.figsize\"] = (30,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_stock.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = y_true-y_pred\n",
    "plt.hist(error, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot error\n",
    "plt.plot(y_true, label='true')\n",
    "plt.plot(y_pred, label='pred')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital=100000\n",
    "n_stocks=5\n",
    "portfolio_value=capital\n",
    "import math\n",
    "for i in range(len(y_test_stock[1])+1):\n",
    "    if(i==len(y_test_stock[1])):\n",
    "      portfolio_value=100000\n",
    "      capital=portfolio_value\n",
    "      print(\"Day {0} \".format(i+1))\n",
    "      predicted_returns=[]\n",
    "      for j in range(len(y_test_stock)):\n",
    "        predicted_returns.append(p_stock[j][i])\n",
    "      predicted_returns=np.array(predicted_returns)\n",
    "      predicted_returns=np.squeeze(predicted_returns,axis=1)\n",
    "      indices = np.argsort(np.abs(predicted_returns))[::-1]\n",
    "      predicted_returns = predicted_returns[indices]\n",
    "    # print(returns)\n",
    "\n",
    "    # returns=np.nan_to_num(returns)\n",
    "    # print(\"returns actual\",returns)\n",
    "\n",
    "      p=[]\n",
    "      # r=[]\n",
    "      count=0\n",
    "      for j in range(len(predicted_returns)):\n",
    "        if(count==n_stocks):\n",
    "          break\n",
    "        # if(np.isnan(returns[j])):\n",
    "        #   continue\n",
    "        else:\n",
    "          p.append(predicted_returns[j])\n",
    "          # r.append(returns[j])\n",
    "          count+=1\n",
    "\n",
    "      p=np.array(p)\n",
    "      weights = (p) / np.sum(np.abs(p))\n",
    "    # print(\"weights new\",weights)\n",
    "\n",
    "      capital_each=portfolio_value*weights\n",
    "      for a in range(count):\n",
    "        print(x[indices[a]],end=\" \")\n",
    "      print()\n",
    "      print(\"capital_each. =\", capital_each)\n",
    "      # print(sum(abs(capital_each)))\n",
    "      print(\"predictions= \",p)\n",
    "      # print(\"Day {0} \".format(i+1))\n",
    "      continue\n",
    "\n",
    "    # if (i==79):\n",
    "    #   capital=97547\n",
    "    #   portfolio_value=capital\n",
    "    predicted_returns=[]\n",
    "    for j in range(len(y_test_stock)):\n",
    "      predicted_returns.append(p_stock[j][i])\n",
    "    # for j in range(len(y_test_crypto)):\n",
    "    #   predicted_returns.append(p_crypto[j][i])\n",
    "    # for j in range(len(y_test_commodity)):\n",
    "    #   predicted_returns.append(p_commodity[j][i])\n",
    "\n",
    "    predicted_returns=np.array(predicted_returns)\n",
    "    # print(\"predicted_returns\",predicted_returns)\n",
    "    returns=[]\n",
    "    for j in range(len(y_test_stock)):\n",
    "      print(i,j)\n",
    "      returns.append(y_test_stock[j][i])\n",
    "\n",
    "    # for j in range(len(y_test_crypto)):\n",
    "    #   returns.append(y_test_crypto[j][i])\n",
    "    # for j in range(len(y_test_commodity)):\n",
    "    #   returns.append(y_test_commodity[j][i])\n",
    "    # print(\"returns actual\",returns)\n",
    "    predicted_returns=np.array(predicted_returns)\n",
    "    returns=np.array(returns)\n",
    "    # print(predicted_returns.shape)\n",
    "    # print(returns.shape)\n",
    "    predicted_returns=np.squeeze(predicted_returns,axis=1)\n",
    "    indices = np.argsort(np.abs(predicted_returns))[::-1]\n",
    "    # print(\"indices= \",indices)\n",
    "    # indices=indices[0]\n",
    "\n",
    "\n",
    "    # Sort both 'a' and 'b' arrays in the same order\n",
    "    returns = returns[indices]\n",
    "    predicted_returns = predicted_returns[indices]\n",
    "    # print(returns)\n",
    "\n",
    "    # returns=np.nan_to_num(returns)\n",
    "    # print(\"returns actual\",returns)\n",
    "\n",
    "    p=[]\n",
    "    r=[]\n",
    "    count=0\n",
    "    for j in range(len(predicted_returns)):\n",
    "      if(count==n_stocks):\n",
    "        break\n",
    "      if(np.isnan(returns[j])):\n",
    "        continue\n",
    "      else:\n",
    "        p.append(predicted_returns[j])\n",
    "        r.append(returns[j])\n",
    "        count+=1\n",
    "\n",
    "    p=np.array(p)\n",
    "    r=np.array(r)\n",
    "    # print(p.shape)\n",
    "    print(p)\n",
    "    print(r)\n",
    "    # print(r.shape)\n",
    "    # print(\"pred retuns\",p)\n",
    "    # print(\"actual retuns\",r)\n",
    "    weights = (p) / np.sum(np.abs(p))\n",
    "    # print(\"weights new\",weights)\n",
    "\n",
    "    capital_each=portfolio_value*weights\n",
    "    cap_diff=0\n",
    "    not_stock=[-1]\n",
    "    for idx in range(n_stocks):\n",
    "      if indices[idx]<len(x):\n",
    "        print(indices[idx])\n",
    "        capital_new=math.floor(capital_each[idx]/open_prices_stock_t[i][indices[idx]])*open_prices_stock_t[i][indices[idx]]\n",
    "        print(\"Quantity of Stock \"+ x[indices[idx]]+\":\"+ str(capital_new/open_prices_stock_t[i][indices[idx]]))\n",
    "        cap_diff+=capital_each[idx]-capital_new\n",
    "        capital_each[idx]=capital_new\n",
    "      else:\n",
    "        not_stock.append(idx)\n",
    "    val=0\n",
    "\n",
    "    # if len(not_stock)==1:\n",
    "    #   val+=cap_diff\n",
    "    # else:\n",
    "    #   capital_each[not_stock[1]]+=cap_diff\n",
    "\n",
    "    print(capital_each)\n",
    "    for a in range(count):\n",
    "      print(x[indices[a]],end=\" \")\n",
    "    print()\n",
    "    print(capital_each.shape)\n",
    "    print(sum(abs(capital_each)))\n",
    "    # print(\"capital_each\",capital_each)\n",
    "    gain_loss=np.dot(capital_each,r)\n",
    "    print(\"Day {0} return is {1}\".format(i+1,gain_loss/portfolio_value*100))\n",
    "    # print(\"gain loss\",gain_loss)\n",
    "    portfolio_value += (gain_loss+val -400)\n",
    "\n",
    "    # capital = portfolio_value\n",
    "    print(\"gain/loss:\",gain_loss,end=\", \")\n",
    "    print(\"portfolio_value:\",portfolio_value)\n",
    "\n",
    "\n",
    "# Print the final portfolio value\n",
    "print(\"Final portfolio value:\", portfolio_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
